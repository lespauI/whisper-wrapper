# Whisper Wrapper
***Disclaimer! This project is 100% AI-generated with [Zencoder.ai](https://zencoder.ai/)***

A Node.js desktop application that provides a user-friendly interface for OpenAI's Whisper speech-to-text model. This application allows you to transcribe audio and video files, as well as record audio directly for transcription.

## Features

- **File Upload**: Upload audio and video files for transcription
- **Audio Recording**: Record audio directly within the application
- **Markdown Formatting**: View and edit transcriptions with Markdown formatting
- **Export Options**: Download transcriptions in various formats
- **Local Processing**: Runs entirely on your local machine
- **Initial Prompt**: Provide custom vocabulary or context to improve transcription accuracy

## Getting Started

### Prerequisites

- Node.js (v16 or higher)
- npm (v8 or higher)
- FFmpeg (for audio/video processing)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/whisper-wrapper.git
   cd whisper-wrapper
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the application:
   ```bash
   npm start
   ```

4. Configure your OpenAI API key:
   - Click the settings button (‚öôÔ∏è) in the application
   - Enter your OpenAI API key
   - Save the settings

## Usage

### Transcribing Files

1. Click the "Upload" button or drag and drop a file into the designated area
2. Select an audio or video file from your computer
3. Wait for the transcription to complete
4. View and edit the transcription in the editor
5. Download the transcription using the "Download" button

### Recording Audio

1. Click the "Record" button to start recording
2. Speak clearly into your microphone
3. Click "Stop" when finished
4. Wait for the transcription to complete
5. View and edit the transcription in the editor
6. Download the transcription using the "Download" button

### Using Initial Prompt for Better Accuracy

You can provide an initial prompt to help the transcription model better recognize specific terms, names, or context:

1. Open the Settings panel
2. Enter your custom vocabulary or context in the "Initial Prompt" field
3. Save the settings
4. Transcribe your audio or video file

The initial prompt will guide the model to better recognize specialized terminology, proper names, or domain-specific vocabulary. For example:

- For medical transcriptions: "Patient John Smith, diagnosis hypertension, medication lisinopril"
- For technical discussions: "JavaScript, React, Node.js, API, frontend, backend, database"
- For business meetings: "Acme Corporation, quarterly report, fiscal year, shareholders, CEO Jane Doe"

## Supported File Formats

### Audio
- MP3
- WAV
- M4A
- FLAC
- OGG

### Video
- MP4
- MOV
- AVI
- MKV
- WEBM

## Architecture

The application follows a client-side MVC architecture with the following components:

- **UI Layer**: Web interface and components
- **Service Layer**: File processing, recording, and transcription services
- **Data Layer**: File storage and configuration management

For more details, see the [architecture documentation](./.architecture/whisper-wrapper/).

## Development Status

### ‚úÖ Phase 1: Project Setup and Basic Structure (COMPLETED)
- ‚úÖ Project initialization and dependencies
- ‚úÖ Electron application shell with main and renderer processes
- ‚úÖ Basic UI with tabbed interface (Upload, Record, Transcription)
- ‚úÖ Service layer foundation (File, Recording, Transcription, Export services)
- ‚úÖ Configuration system with electron-store
- ‚úÖ Development tools setup (ESLint, Prettier, Jest)
- ‚úÖ Build and packaging scripts
- ‚úÖ Basic test suite

### ‚úÖ Phase 2: Core Functionality (COMPLETED)
- ‚úÖ File upload and processing implementation
- ‚úÖ Whisper API integration
- ‚úÖ Error handling and validation
- ‚úÖ IPC communication system
- ‚úÖ Native file dialogs and drag-and-drop
- ‚úÖ Real-time transcription progress
- ‚úÖ Settings management with API key validation

### ‚úÖ Phase 3: Recording Functionality (COMPLETED)
- ‚úÖ Audio capture using Web Audio API
- ‚úÖ Recording controls and visualization
- ‚úÖ Audio processing and storage
- ‚úÖ Recording service with pause/resume functionality
- ‚úÖ Recording settings and quality management
- ‚úÖ Recording history and validation
- ‚úÖ Integration tests for recording workflow

### ‚úÖ Phase 4: Transcription Display and Editing (COMPLETED)
- ‚úÖ Enhanced transcription display with real-time editing
- ‚úÖ Auto-save functionality with 2-second delay
- ‚úÖ Undo/redo system with 50-step history management
- ‚úÖ Find & replace with case-insensitive search
- ‚úÖ Export options (TXT, Markdown, JSON formats)
- ‚úÖ Keyboard shortcuts for productivity
- ‚úÖ Word and character count display
- ‚úÖ Draft persistence across sessions
- ‚úÖ Copy to clipboard functionality
- ‚úÖ Comprehensive testing (33 tests passing)

### üìã Phase 5: UI Refinement and Testing (PLANNED)
- UI polish and animations
- Comprehensive testing
- Performance optimization
- Accessibility improvements

## Development

### Project Structure

```
whisper-wrapper/
‚îú‚îÄ‚îÄ src/                # Source code
‚îÇ   ‚îú‚îÄ‚îÄ main/           # Electron main process
‚îÇ   ‚îú‚îÄ‚îÄ renderer/       # Electron renderer process
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Service layer
‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ config/         # Configuration
‚îú‚îÄ‚îÄ tests/              # Test files
‚îî‚îÄ‚îÄ ...
```

### API Usage

You can use the LocalWhisperService programmatically in your own code:

```javascript
const { LocalWhisperService } = require('./src/services/localWhisperService');

// Initialize the service
const whisperService = new LocalWhisperService();

// Set an initial prompt with specialized vocabulary
whisperService.setInitialPrompt("Technical terms: Node.js, JavaScript, React, Redux, TypeScript, API");

// Transcribe a file
async function transcribeMyFile() {
  try {
    const result = await whisperService.transcribeFile('/path/to/audio.mp3', {
      model: 'medium',
      language: 'en',
      translate: false,
      threads: 4
    });
    
    console.log('Transcription:', result.text);
    console.log('Segments:', result.segments);
  } catch (error) {
    console.error('Transcription failed:', error);
  }
}

transcribeMyFile();
```

### Available Scripts

In the project directory, you can run:

#### `npm start`

Runs the app in development mode.

#### `npm test`

Launches the test runner.

#### `npm run build`

Builds the app for production to the `dist` folder.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [OpenAI Whisper](https://openai.com/research/whisper) for the speech recognition model
- [Electron](https://www.electronjs.org/) for the desktop application framework
- [FFmpeg](https://ffmpeg.org/) for audio/video processing
